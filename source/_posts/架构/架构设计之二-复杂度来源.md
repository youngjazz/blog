---
title: 架构设计之二--复杂度来源
date: 2018-06-15 11:41:05
tags: 架构设计
categories: 技术
---

在背景阶段我们分析了架构设计的主要目的是解决软件系统中复杂度带来的问题，那么软件复杂度的来源是什么？

## 复杂度来源：高性能

<!--more-->

电子计算机从电子管到晶体管到集成电路，运算性能从每秒几次到每秒几亿次。性能越来越高，起复杂度也是越来越高。软件系统也存在这样的现象，Google能够支撑每秒海量搜索，与此同时，软件系统规模也从单台扩展到上万台计算机。当然，技术发展带来的性能提升，不一定会带来复杂度的提升，例如：硬件重纸带->磁带->磁盘->SSD, 并没有带来系统复杂度的显著提升。因为新技术会逐步替代旧技术，这种情况直接选择新技术就好了。但如果不是新技术淘汰旧技术，而是开辟了一个全新的技术领域，才会给软件系统带来复杂度，因为系统设计的时候要在这些技术之间做权衡取舍或者组合。就如同火车不能替代飞机一样，我们需要综合考虑价格、时间、舒适度等因素。

软件系统中高性能的复杂度体现在两个方面：**单机为提高性能带来的复杂度**和**集群为提高性能带来的复杂度**

### 单机复杂度

计算机内部复杂度最关键的地方就是操作系统。计算机的性能本质上是有硬件发展驱动的，尤其是cpu的性能。操作系统是系统的运行环境，操作系统的复杂度决定软件系统复杂度。

操作系统和性能相关的就是**进程**和**线程**。最初计算机没有操作系统，只有输入、计算和输出功能，为了解决手工输入的低效问题，批处理操作系统应运而生，批处理将指令预先写下来，形成指令清单（就是我们常说的“任务”），操作系统负责读取清单指令并执行，性能大大提高。

但是有一个明显的缺点：批处理程序一次只能执行一个任务，如果某个任务从I/O设备上读取大量数据，在I/O操作过程中，CPU其实是空闲的，而这段时间本来可以用于其他计算。

为了进一步提升性能，人们发明了“进程”，用进程来对应一个任务。每个任务都有自己的独立空间，进程之间互不相关，由操作系统进行调度。此时的CPU还没有多核和多线程的概念，为了达到多进程并行运行，采取了分时的方式。即把CPU的时间分成很多段，每段时间只能处理某个进程的指令。由于CPU处理速度很快，用户感觉到的好像是多进程在并行处理，实际还是串行处理的。

多进程有独立的内存空间，互不相关。但如果能够在运行时通信，会让任务设计变得更加灵活高效。如A任务将结果存储，B再从存储中读取结果进行计算，不仅效率低，而且程序设计复杂。为了解决这个问题，进程间通信方式被设计出来了，包括管道、消息队列、信号量、共享存储等。

多进程让多任务能够并行处理，但本身扔有很多缺点，单个进程内部仍是串行。而实际上进程内部子任务并不要求按严格先后顺序执行，也需要实现并行。如餐厅排队，点餐，服务员调度，收银可以同时践行，不应该出现因为某个顾客结账问题导致别的顾客不能点餐的问题。为此，人们发明了“线程”，线程是进程内部的子任务，但这些子任务共享一份进程数据。为了保证数据正确性，于是发明了**互斥锁机制**。此时操作系统**调度**的最小单位就变成了线程，而进程变成了系统**分配资源**的最小单位。

此时多进程多线程让多任务并行处理的性能大大提升，本质上仍然是分时系统，并不能做到时间上的真正并行。解决这个问题的方式就是让多个cpu同时执行计算。目前这样的解决方案有3种：SMP（Symmetric Multi-Processor，对称多处理器结果）、NUMA（Non-Uniform Memory Access，非一致存储访问结构）、MPP（Massive Parallel Processing，海量并行处理结构）。目前流行的多核处理器就是SMP方案。

然而这些技术不是最新的一定就是最好的，也不是非此即彼的选择。我们需要结合业务进行分析、判断、选择、组合。举个例子：Nginx可以选择多进程也可以选择多线程，JBoss采用多线程，Redis采用单进程，Memcache采用多线程，这些系统都实现了高性能，但内部差异却很大。

### 集群复杂度

随着业务越来越复杂，单台的性能无论如何都不能支撑，必须采用集群的方式达到高性能。但并不是仅仅通过增加机器这么简单，常见方式：

**1.任务分配**

任务分配指的是每个单台机器都能处理完整业务，不同的任务分配到不同的机器上执行。从简单的一台服务器变成两台开始讲解任务分配带来的复杂性，架构示意图如下：

![任务分配架构](http://p7b5cwgjy.bkt.clouddn.com/%E9%9B%86%E7%BE%A4-%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D.png)
相对于单台服务器复杂性体现在：
- 需要额外增加任务分配器器，可以使硬件网络设备(F5、交换机等)，可以是软件(如LVS)，也可能是负载均衡软件(Nginx，HAProxy)或者其他自研系统等。选择合适的任务分配器是一件复杂的事情，需要综合考虑性能、成本、可维护性、可用性等各方面因素。
- 任务分配器和真正的业务服务器之间有连接和交互，需要选择合适的连接方式，并且对连接进行管理。例如：建立连接、连接检测、连接中断后如何处理等。
- 需要增加任务分配算法。是采用轮询、还是按权重分配、或者按照负载进行分配。如果按负载分配，则业务服务器还要上报自己的状态给任务分配器。

上面只是简单一台机器假设能够处理每秒5000次业务请求，两台理论能够处理10000次请求，实际性能一般按照8折大约8000次左右。如果性能要求继续提高，每秒10万次，上面的架构就出现了新的问题，不是简单增加到25台服务器即可，因为随着性能的增加，任务分配器本身又会成为性能瓶颈，单台任务分配器也就不够用了，任务分配器就变成了集群，架构如下：
![复杂的任务分配架构](http://p7b5cwgjy.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-07-02%2023.12.29.png)

这比两台业务服务器的架构要复杂，主要体现在：
- 任务分配器从一台变为多台，图中用户分配是指将不同的用户分配的不同的分配器上，常见的方法包括DNS轮询、只能DNS、CDN（Content Delivery Network)、GSLB设备(Global Server Load Balance，全局负载均衡)等。
- 任务分配器和业务服务器由1对多变成多对多的网状结构
- 机器从3台扩展到30台(一般任务分配器比业务服务器少，这里假设5-25的比例)，状态管理、故障处理复杂度大大增加
上线的业务不一定就是指某个具体业务，也可能是计算、存储、缓存等。比如Memcache集群架构。
**2.任务分解**
通过任务分配解决了单台服务器性能瓶颈。但如果业务本身越来越复杂，单纯只通过任务分配的方式扩展性能，收益会越来越低。业务简单1台扩展到10台假设可以带了8倍性能提升，而复杂业务可能只能带来5倍提升。造成这种现象的主要原因是业务复杂度越来越高，单台机器处理性能就回越来越低。为了能够继续提升性能，我们采用第二种方式：任务分解。
![任务拆分](http://p7b5cwgjy.bkt.clouddn.com/%E9%9B%86%E7%BE%A4-%E4%BB%BB%E5%8A%A1%E6%8B%86%E5%88%86.png)
将大一统的复杂业务系统，拆分为小而简单的多个系统配合的业务系统。性能提升体现在：
- 简单系统更容易做到高性能。功能越简单，影响性能的点就越少，可以更加针对性的优化。而复杂系统很难找到关键性能点，A关键性能提升了，可能无意减低了B性能，整体性能有可能不升反降。
- 可以针对单个任务进行扩展。拆分独立子系统后，整个系统的瓶颈更容易发现，只需针对瓶颈子系统进行性能优化或提升即可，无需改动整个系统，风险会小很多。如用户增长过快，注册登录子系统出现瓶颈，只需优化注册登录子系统(代码优化或者粗暴加机器)，消息逻辑，LBS可能就无需改动。
**是不是子系统拆的越多越好呢？**其实并不是这样的，这样有可能让系统性能下降，因为系统拆分太细，系统间的调用次数会呈指数级别上升，而系统调用是通过网络传输，性能远比系统内部函数调用低得多。对于架构设计来说，如何把握这个粒度就非常关键了。

## 复杂度来源：高可用

参考维基百科对高可用的定义：

> 系统无中断的执行器功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。

洽洽难点就在**无中断**上，无论单个硬件还是单个软件都不能无中断，硬件会出故障，软件会出bug；除此之外，外部环境导致的不可用更加不可避免、不受控制。如断电、水灾、地震等而且这些故障影响程度更加严重、而且难以预测和规避。

所以系统高可用方案五花八门，但万变不离其宗，本质上都是“**冗余**”实现高可用。通俗讲就是一台机器不够就两台，一个机房可能断电就两个机房，一个通道可能故障就用两条。单纯从形式上看，是和前面的高性能是一样的都是通过增加机器来解决问题。但本质上又是有根本区别的：**高性能增加机器目的在扩展处理性能，高可用增加机器目的在于冗余处理单元**。正是冗余带来了复杂性：

### 计算高可用

计算有一个特点是：无论在哪台机器上计算，同样的算法和输入数据，输出的结果是一样的。和高性能的双机架构一样，复杂度也是类似的

- 需要增加一个任务分配器，选择合适的任务分配器是一件复杂的事情。需要综合考虑性能、成本、可维护性、可用性等因素
- 任务分配器和业务服务器之间有连接和交互，连接的建立，连接检测，连接中断如何处理
- 任务分配算法。例如常见的双击算法主备、主主，主备可细分冷备、温备、热备。

更复杂些计算高可用集群，分配算法更加复杂，1主3备，2主2备，3主1备，4主0备。具体采用哪种需要结合业务需求分析判断。例如zookeeper采用的是一主多备，而Memcached采用全主0备。

### 存储高可用

恰恰难点就是“存储”，存储和计算的本质区别就是：**将数据从一台机器搬到另一台机器，需要经过线路传输**，线路传输的速度是毫秒级，同机房几毫秒，不同机房几十甚至上百毫秒。如北京到广州机房ping延时大约50ms，不稳定有可能1s还要多。

毫秒对于人类虽然几乎没有感觉，但是对高可用系统就是本质不同了，这意味着整个系统在某个时间点数据是不一致的。按照**数据+逻辑=业务**这个公式来看，数据不一致，即使逻辑一样，最后的业务就不一样了。以银行储蓄为例，A在银行储蓄1万元，北京机房记录该笔存款操作，用户查询余额时数据还没有同步至上海机房，用户体验肯定不好。

除了物理传输速度限制，传输线路本身也存在可用性问题，线路可能中断、线路拥塞、异常（错包，丢包），而且线路故障往往特别长，短的十几分钟，长的几小时都有可能。如2015年支付宝光缆被挖段，影响超过4小时。

所以**存储高可用的难点不在如何备份数据，而在于如何减少或者规避数据不一致对业务的影响**。

### 高可用状态决策

无论计算还是存储高可用，其基础状态都是“**状态决策**”，即判断当前状态是正常还是异常，如果出现了异常就要采取行动保证高可用。如果状态本身就判断错误和偏差，那后续任何行动都是无意义的。但是实践过程中又有这样一个矛盾：**通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确。**对常见决策方式进行分析：
**1、独裁式**

独裁式决策指的是存在一份独立的决策主体，我们称之为“决策者”，负责信息的收集然后进行决策，所有冗余的个体-上报者，都将状态上报给决策者。

![独裁式](http://p7b5cwgjy.bkt.clouddn.com/%E9%AB%98%E5%8F%AF%E7%94%A8%E5%86%B3%E7%AD%96%E7%8A%B6%E6%80%81-%E7%8B%AC%E8%A3%81%E5%BC%8F.png)
独裁式决策不会出现决策混乱的问题，因为只有一个决策者，但问题洽洽出在这一个决策者上。当决策者发生故障，整个系统都无法实现准确的决策。如果决策者本身有做了一套状态决策，那就陷入了一个递归的死循环。

**2、协商式**
协商式指的是，两个独立的个体通过交流信息，然后根据规则决策，**最常见协商式决策的是主备决策**。
![协商式](http://p7b5cwgjy.bkt.clouddn.com/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%8A%B6%E6%80%81%E5%8D%8F%E5%95%86%E5%BC%8F.png)
这个架构基本协商规则可以设计成：两台服务启动时都是备机，建立连接，交换信息，某一台服务器做出决策成为主机，另一台保持备机。
协商式架构本身不复杂，其难点在于，如果两者信息交换出现问题（如连接出现中断），那么决策如何做？
- 连接中断，备机认为主机故障，那么备机需要升级为主机，实际上主机并没有故障，那额系统就出现了多主机，这与设计初衷(1主1备)不符合。
- 连接中断，不认为主机故障，备机不升级为主机。而主机真的发生了故障，那么系统就没有了主机。与设计初衷不符合
- 如果为了规避连接中断对状态决策带来的影响，可以增加更多的连接。例如，双连接、三连接。这样虽然能够降低连接中断对状态带来的影响（注意：只能降低，不能彻底解决），但同时又引入了这几条连接之间信息取舍的问题，即如果不同连接传递的信息不同，应该以哪个连接为准？实际上这也是一个无解的答案，无论以哪个连接为准，在特定场景下都可能存在问题。

综合分析，协商式状态决策在某些场景总存在一些问题的。

**3、民主式**
民主式指的是多个独立的个体通过投票的方式进行状态决策。例如ZK集群选举leader是采用的这种方式。
![民主式](http://p7b5cwgjy.bkt.clouddn.com/%E9%AB%98%E5%8F%AF%E7%94%A8%E5%86%B3%E7%AD%96%E7%8A%B6%E6%80%81%E6%B0%91%E4%B8%BB%E5%BC%8F.png)
民主式和协商式比较类似，基础都是独立个体之间的信息交换，每个个体做出自己的决策，然后按照**多者胜出**的原则确定最终状态。不同点在于民主式比协商式要复杂的多。zookeeper的选举算法是Paxos, 绝大多数的人都云里雾里，更不用说代码实现了。
**除了算法复杂，民主式决策还有个固有缺陷：脑裂**。这个词来源于医学，指人体左右大脑半球的连接被切断后，左右脑因为**无法交换信息**，导致**各自做出决策**，然后身体受到两个大脑分别控制，会做出各种奇怪的动作。例如：当一个脑裂患者更衣时，他有时会一只手将裤子拉起，另一只手却将裤子往下脱。脑裂的根本原因是，原来统一的集群因为连接中断，造成了两个独立分隔的子集群，每个子集群单独进行选举，于是选出了 2 个主机，相当于人体有两个大脑了。
![脑裂](http://p7b5cwgjy.bkt.clouddn.com/%E6%B0%91%E4%B8%BB%E5%BC%8F%E7%AE%97%E6%B3%95%E7%BC%BA%E9%99%B7-%E8%84%91%E8%A3%82.png)
从图中可以看到，正常状态的时候，节点 5 作为主节点，其他节点作为备节点；当连接发生故障时，节点 1、节点 2、节点 3 形成了一个子集群，节点 4、节点 5 形成了另外一个子集群，这两个子集群的连接已经中断，无法进行信息交换。按照民主决策的规则和算法，两个子集群分别选出了节点 2 和节点 5 作为主节点，此时整个系统就出现了两个主节点。这个状态违背了系统设计的初衷，两个主节点会各自做出自己的决策，整个系统的状态就混乱了。
为了解决脑裂问题，民主式决策的系统一般采用**投票节点必须超过系统总节点半数**的规则来处理，如图4、5节点投票数只有2没有达到5的一半，因此这个子集群不能进行选举。这种方式虽然解决了脑裂问题，但是降低了整体系统可用性。如果1、2、3真是故障而非连接中断，此时系统就选不出leader，而导致真个系统宕机，即便4、5节点是正常的。

综合分析，无论采取什么样的方案，状态决策都不可能做到任何场景下都没有问题，但完全不做高可用方案又会产生更大的问题，如何选取适合系统的高可用方案，也是一个复杂的分析、判断和选择的过程。

## 复杂度来源：可扩展

可扩展性是指系统为了应对将来需求而提供的一种扩展能力，当心的需求出现时，系统不需要或仅需要少量的修改就可以支持，无需整个系统重构或者重建。新的需求不断提出，因此可扩展性尤其重要。在软件开发领域，面向对象思想的提出，就是为解决可扩展性带来的问题。后来的设计模式，更是将可扩展性做到极致。设计具备良好可扩展性的系统，要具备两个基本条件：**正确预测变化、完美封装变化**，但要达成这两个条件，本身就是一件复杂的事情。

### 预测变化
“唯一不变的是变化”

有一句谚语，“唯一不变的是变化”，但是又不能在架构设计的每个点都考虑扩展性，这样就很难落地了。预测的复杂性在于：
- 不能每个设计点都考虑扩展性
- 不能完全不考虑扩展性
- 所有的预测都存在错误的可能性

### 应对变化
第一种应对变化的常见方案：**将变化封装为一个“变化层”， 将不变的封装为一个独立的“稳定层”**。无论变化层依赖稳定层还是稳定层依赖变化层都是可以的，需要根据具体业务情况设计。
i[变化与封装](http://p7b5cwgjy.bkt.clouddn.com/%E5%8F%98%E5%8C%96%E5%B0%81%E8%A3%85.png)
无论采用哪种形式，通过剥离变化层和稳定层的方式变化，都会带来两个主要复杂性的问题。
1.系统需要设计变化层和稳定层
哪些属于变化层，哪些属于稳定层，有些不是那个明确，需要结合业务和经验判断。

2.需要设计变化层和稳定层之间的接口
接口设计同样至关重要，对于稳定层来说，接口肯定是越稳定越好；但对于变化层来说，在有差异的多个实现方式中找出共同点，并且还要保证当加入新的功能时原有的接口设计不需要太大修改，这是一件很复杂的事情。

第二种应对变化的方案：**提炼一个“抽象层“和一个”实现层”**。抽象层是稳定的，实现层是可以根据具体业务需要定制开发，当加入新功能时，只需要增加实现，无需修改抽象层。这种方案典型的实践就是设计模式和规则引擎。


## 复杂度来源：低成本、安全、规模
### 低成本
当我们高性能的架构时，通用的手段是增加更多的服务器来满足“高性能”和“高可用的”，而低成本就需要我们减少服务器的数量来达到低成本的目标。因此低成本与高性能和高可用是冲突的，所以低成本不成为架构设计的首要目标，而是附加约束。
底成本打来的主要复杂度体现在，**往往只有通过“创新”才能达到低成本的目标**。这里的创新既包括开创一个新的技术领域，也包括引入新技术，如果没有这样的技术那就需要创造新技术。
类似的例子：
- NoSQL（Memcache, Redis等）的出现时为了解决关系型数据库无法高并发访问带来的访问压力
- 全文搜索引擎(Sphinx， ElasticSearch， Solr)的出现是为了解决like效率低的问题
- Hadoop的出现是为了解决传统文件系统无法应对海量数据的存储和计算的问题
- LinkedIn为了处理每天5千亿事件，开发了高效的Kafka
相对来说创造新技术的复杂度很高。小公司基本都是靠引入新技术来达到低成本。
### 安全
安全是个庞大而又复杂的技术领域。并且一旦出了问题，对业务和企业形象影响非常大。从技术的角度上安全可以分为两类：一类是功能上安全，一类是架构的安全。
1.功能安全
常见的XSS攻击、CSRF攻击、SQL注入、Windows漏洞、密码破解等本质是因为系统实现有漏洞。现如今的开发框架已经集成了常见的安全功能。但是框架本身又会有漏洞，如struts2多次曝出调用远程代码的高危漏洞。
2.架构安全
如果说功能安全是“防小偷”，架构安全就是“防强盗”。小偷是偷东西，强盗是搞破坏。传统的架构安全主要依靠防火墙。防火墙的主要功能就是隔离网络，通过网络划分成不同的区域，制定出不同区域之间的**访问控制策略**来控制不同信任程度区域间传送的数据流。下图是典型的银行系统的安全架构
i[架构安全](http://p7b5cwgjy.bkt.clouddn.com/%E6%9E%B6%E6%9E%84%E5%AE%89%E5%85%A8.png)
防火墙的功能虽然强大，但性能一般，所以在传统的银行和企业应用领域应用较多。但在互联网领域，防火墙的应用场景并不多。因为互联网的业务具有海量用户访问和高并发的特点，防火墙的性能不足以支撑；尤其是互联网领域的 DDoS 攻击，轻则几 GB，重则几十 GB。2016 年知名安全研究人员布莱恩·克莱布斯（Brian Krebs）的安全博客网站遭遇 DDoS 攻击，攻击带宽达 665Gbps，是目前在网络犯罪领域已知的最大的拒绝服务攻击。这种规模的攻击，如果用防火墙来防，则需要部署大量的防火墙，成本会很高。例如，中高端一些的防火墙价格 10 万元，每秒能抗住大约 25GB 流量，那么应对这种攻击就需要将近 30 台防火墙，成本将近 300 万元，这还不包括维护成本，而这些防火墙设备在没有发生攻击的时候又没有什么作用。也就是说，如果花费几百万元来买这么一套设备，有可能几年都发挥不了任何作用。
DDos攻击最大影响是大量消耗机房的出口带宽。不管防火墙的处理能力有多强，当出口带宽被耗尽是，整个业务在用户看来都是不可用的。
基于上述原因，互联网系统的架构安全目前并没有太好的设计手段来实现，更多地是依靠运营商或者云服务商强大的带宽和流量清洗的能力，较少自己来设计和实现。
### 规模
规模带来复杂度的主要原因就是“量变引起质变”，当数量超过一定的阈值后，复杂度会发生质的变化。常见的规模带来的复杂度有：
1.系统功能越多，导致系统复杂度指数级上升。
我们可以使用简单抽象模型计算一下，假设系统间两两相关，系统复杂度=功能数量+功能之间的连接数
- 3个功能的系统复杂度 = 3 + 3
- 8个功能的系统复杂度 = 8 + 28

2.数据越来越多，系统复杂度发生质变
数据太多以后，传统的数据收集、加工、存储、分析的手段和工具已经无法适应，必须应用新的技术才能解决。
即使我们的数据没有达到大数据规模，数据的增长也可能给系统带来复杂性。最典型的例子莫过于使用关系数据库存储数据，我以 MySQL 为例，MySQL 单表的数据因不同的业务和应用场景会有不同的最优值，但不管怎样都肯定是有一定的限度的，一般推荐在 5000 万行左右。如果因为业务的发展，单表数据达到了 10 亿行，就会产生很多问题，例如：
- 添加索引会很慢，可能需要几小时，这几小时数据是无法插入的，相当于业务基本停机了
- 修改表结构和索引存在类似问题，可能耗时更长
- 即使有索引，索引性能也会降到很低，因为数据量太大
- 数据备份耗时很长
- ...

因此Mysql单表数据量过大是，我们必须考虑拆分为多表，这个拆分过程也会引入更多的复杂性。例如：
- 拆表的规则是什么？
- 拆完表后查询如何处理？
这个我们以后再聊